{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "#current_dir = os.getcwd()\n",
    "HOME_DIR = '/home/denys/projects/ml-models/kaggle/dog-breed-identification/'\n",
    "DATA_HOME_DIR = HOME_DIR + 'data/'\n",
    "#DATA_HOME_DIR = HOME_DIR + '/data/sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import plot_learning_curve\n",
    "from utils import save_array, load_array, onehot\n",
    "from utils import get_batches, get_data,  get_breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"data/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_data() got an unexpected keyword argument 'target_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2e588a381352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m244\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m244\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_HOME_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_data() got an unexpected keyword argument 'target_size'"
     ]
    }
   ],
   "source": [
    "train_data = get_data(DATA_HOME_DIR+'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(DATA_HOME_DIR + 'train_244_244.data', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_array(DATA_HOME_DIR+'train_244_244.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9225 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size = (244,244)\n",
    "batches = get_batches(DATA_HOME_DIR + 'train', shuffle=False, batch_size=1, target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = batches.classes\n",
    "train_labels = onehot(train_classes)\n",
    "train_filenames = batches.filenames\n",
    "train_class_indices = batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = DATA_HOME_DIR + \"models/\"\n",
    "logs_path = HOME_DIR + \"logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=False, random_state=1) #shuffle=False to avoid data leakega during assamble\n",
    "kf.get_n_splits(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "model_name = \"vgg16\"\n",
    "date_of_start = \"0203_1625\"\n",
    "csv_logger = CSVLogger(logs_path + model_name + date_of_start + '.log', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "\n",
    "# = {\"vgg16\": VGG16(weights='imagenet', include_top=False),\n",
    "         # \"resnet50\" : ResNet50(weights='imagenet', include_top=False),\n",
    "          #\"InceptionV3\": InceptionV3(weights='imagenet', include_top=False),\n",
    "          #\"InceptionResNetV2\": InceptionResNetV2(weights='imagenet', include_top=False)}\n",
    " #        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               24120     \n",
      "=================================================================\n",
      "Total params: 14,844,256\n",
      "Trainable params: 128,144\n",
      "Non-trainable params: 14,716,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "print model_name\n",
    "x = BatchNormalization()(base_model.output)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(120, activation='softmax')(x)\n",
    "    \n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', metrics=[\"accuracy\"], loss='categorical_crossentropy')\n",
    "    \n",
    "model.load_weights(model_path + model_name + '_0203_1402.h5')\n",
    "print model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "512/512 [==============================] - 534s 1s/step - loss: 1.5589 - acc: 0.5807 - val_loss: 0.2546 - val_acc: 0.9208\n",
      "Epoch 2/10\n",
      "512/512 [==============================] - 532s 1s/step - loss: 1.3038 - acc: 0.6323 - val_loss: 0.3773 - val_acc: 0.8783\n",
      "Epoch 3/10\n",
      "512/512 [==============================] - 532s 1s/step - loss: 1.1575 - acc: 0.6585 - val_loss: 0.4802 - val_acc: 0.8545\n",
      "Epoch 4/10\n",
      "512/512 [==============================] - 532s 1s/step - loss: 1.0944 - acc: 0.6826 - val_loss: 0.5704 - val_acc: 0.8225\n",
      "Epoch 5/10\n",
      "512/512 [==============================] - 532s 1s/step - loss: 1.0042 - acc: 0.6991 - val_loss: 0.6854 - val_acc: 0.7844\n",
      "Epoch 6/10\n",
      "512/512 [==============================] - 532s 1s/step - loss: 0.9856 - acc: 0.7074 - val_loss: 0.7455 - val_acc: 0.7774\n",
      "Epoch 7/10\n",
      "511/512 [============================>.] - ETA: 0s - loss: 0.9345 - acc: 0.7244"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "for train_index, valid_index in kf.split(train_data):\n",
    "#    model.optimiser.lr = 0.0000001\n",
    "\n",
    "    train_split, valid_split = train_data[train_index], train_data[valid_index]\n",
    "    train_labels_split, valid_labels_split = train_labels[train_index], train_labels[valid_index]\n",
    "\n",
    "        #rotation_range=15, width_shift_range=0.1, \n",
    "                               #height_shift_range=0.1, zoom_range=0.2, horizontal_flip=True\n",
    "    batches = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, \n",
    "                                       height_shift_range=0.1, zoom_range=0.2, horizontal_flip=True).flow(train_split, train_labels_split, batch_size=batch_size, shuffle=True)\n",
    "    val_batches = image.ImageDataGenerator().flow(valid_split, valid_labels_split, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    model.fit_generator(batches, steps_per_epoch=batches.n / batch_size, epochs=10, validation_data=val_batches, \n",
    "                        validation_steps=val_batches.n, verbose=1, callbacks=[csv_logger])\n",
    "            \n",
    "    model.save_weights(model_path + model_name + date_of_start + '.h5')\n",
    "   # print model.test_on_batch(valid_data, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c0a1ec6d9f1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"vgg160203_1402.log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'log_path' is not defined"
     ]
    }
   ],
   "source": [
    "plot_learning_curve(log_path + \"vgg160203_1402.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_predictions(pred_probs):\n",
    "    prepared_result = []\n",
    "    max_probs = get_max_prob_per_item(pred_probs)\n",
    "    for row, max_prob in zip(pred_probs, max_probs):\n",
    "        prepared_result.append(np.vectorize(lambda prob: prob if prob == max_prob else 0.0)(row))\n",
    "    return prepared_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10357 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "test_batches = gen.flow_from_directory(DATA_HOME_DIR + \"test\", target_size=target_size, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batches.reset()\n",
    "filenames = test_batches.filenames\n",
    "test_probs = model.predict_generator(test_batches, len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "unknown/012ca7efe684c5cdfb83f35e8fbafe1b.jpg\n"
     ]
    }
   ],
   "source": [
    "len(test_probs)\n",
    "print np.argmax(test_probs[54])\n",
    "print test_batches.filenames[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ids(filenames):\n",
    "    return np.vectorize(lambda filename: filename[-36:-4])(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10357"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = get_ids(test_batches.filenames)\n",
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = sorted(train_class_indices.keys())\n",
    "header.insert(0, \"id\")\n",
    "header = ','.join(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_ids, np.clip(test_probs, 0.05, 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('vgg_02031402_clip.csv', result, delimiter=',', header=header, comments=\"\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            136         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            264         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            36          add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 436\n",
      "Trainable params: 436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "input1 = keras.layers.Input(shape=(16,))\n",
    "x1 = keras.layers.Dense(8, activation='relu')(input1)\n",
    "input2 = keras.layers.Input(shape=(32,))\n",
    "x2 = keras.layers.Dense(8, activation='relu')(input2)\n",
    "added = keras.layers.Add()([x1, x2])  # equivalent to added = keras.layers.add([x1, x2])\n",
    "\n",
    "out = keras.layers.Dense(4)(added)\n",
    "model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_pool_cnn_model = conv_pool_cnn(model_input)\n",
    "all_cnn_model = all_cnn(model_input)\n",
    "nin_cnn_model = nin_cnn(model_input)\n",
    "\n",
    "conv_pool_cnn_model.load_weights('weights/conv_pool_cnn.29-0.10.hdf5')\n",
    "all_cnn_model.load_weights('weights/all_cnn.30-0.08.hdf5')\n",
    "nin_cnn_model.load_weights('weights/nin_cnn.30-0.93.hdf5')\n",
    "\n",
    "models = [conv_pool_cnn_model, all_cnn_model, nin_cnn_model]\n",
    "\n",
    "def ensemble(models, model_input):\n",
    "    \n",
    "    outputs = [model.outputs[0] for model in models]\n",
    "    y = Average()(outputs)\n",
    "    \n",
    "    model = Model(model_input, y, name='ensemble')\n",
    "    \n",
    "    return model\n",
    "ensemble_model = ensemble(models, model_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
